---
title: "Assignment 3 _ Movehub City Rankings"
author: "Bablu Prasad (23104917)"
format: html
editor: visual
---

### Introduction:

Move Hubb know that everyone has different reasons for moving. Thatâ€™s why they have ranked some of the worlds top cities in relation to key factors, like safety, property affordability and climate. Simply selecting the factors most important to you and they will show you the best cities for you to consider!

For more details visit here [Click here](https://www.movehub.com/city-rankings/)

### We have total 3 files downloaded from [Kaggle](https://www.kaggle.com/datasets/blitzr/movehub-city-rankings) :

-   movehubqualityoflife.csv

-   movehubcostofliving.csv

-   cities.csv (merged LAT & LONG from data got from -\> Downloadable Geographic Databases \| Simplemaps.com)

![Data Stream Flow](data_stream_flow.jpg){fig-align="center" width="517"}

### Importing important Libraries:

```{r}
# Suppress warnings for conflicts when loading libraries 
options(warn.conflicts = TRUE) 
# Load libraries with conflicts suppressed 
suppressWarnings({ 
  library(tidyverse, exclude = c("annotate", "combine"))  # For data manipulation and visualization
  library(RColorBrewer)  # For color palettes
  library(tm)  # For text mining and preprocessing
  library(wordcloud)  # For creating word clouds
  library(gridExtra)  # For arranging plots
  library(leaflet)  # For interactive maps
  library(corrplot)  # For visualizing correlation matrices
  library(caTools)  # For data splitting
  library(MASS, exclude = c("dplyr"))  # For statistical functions
}) 
# Reset options to default 
options(warn.conflicts = FALSE)

```

### Loading the all 3 datasets:

```{r}
cost_of_living <- read.csv("E:\\\\Assigment3\\\\movehubcostofliving.csv") 
quality_of_life <- read.csv("E:\\\\Assigment3\\\\movehubqualityoflife.csv") 
cities <- read.csv("E:\\\\Assigment3\\\\cities.csv")

```

### Dataset Understanding:

```{r}
# Display all dataframes 
head(cost_of_living)
head(quality_of_life)
head(cities)
```

```{r}
# Checking datatype 
print("Datatype of 'cost_of_living' dataset:")
print(str(cost_of_living))
print("Datatype of 'quality_of_life' dataset:")
print(str(quality_of_life))
print("Datatype of 'cities' dataset:")
print(str(cities))

```

```{r}
# Ensuring city names are consistent across datasets 
cost_of_living$City <- tolower(cost_of_living$City)
quality_of_life$City <- tolower(quality_of_life$City)
cities$City <- tolower(cities$City)

```

```{r}
# Display the dimensions of datasets 
print("Dimension of row-columns of 'cities' dataset:")
print(dim(cities))
print("Dimension of row-columns of 'cost of living' dataset:")
print(dim(cost_of_living))
print("Dimension of row-columns of 'quality of life' dataset:")
print(dim(quality_of_life))
```

### Merging the data set based on City:

```{r}
# Merge the datasets on the 'City' column 
combined_data <- cost_of_living %>%
  inner_join(quality_of_life, by = "City") %>%
  inner_join(cities, by = "City")

```

```{r}
# displaying merged dataframe
head(combined_data)
```

```{r}
# Checking merged dataframe datatype 
print("Datatype of 'combined_data' dataset:")
print(str(combined_data))

```

### Data Preprocessing:

```{r}
# Convert LAT and LONG columns to numeric if they aren't already 
combined_data$LAT <- as.numeric(as.character(combined_data$LAT))
combined_data$LONG <- as.numeric(as.character(combined_data$LONG))

```

```{r}
#checking the null value 
combined_data[combined_data == "N/A"]<-NA 
colSums(is.na(combined_data)) 

```

```{r}
# Define numerical and categorical columns 
numerical_columns <- names(combined_data)[sapply(combined_data, is.numeric)]
categorical_columns <- names(combined_data)[sapply(combined_data, function(x) is.factor(x) | is.character(x))]
```

```{r}
# Summary statistics 
summary(combined_data)
```

### Exploratory Data Analysis:

#### 1. Count of Unique Values in Each Categorical Column:

```{r}
# Count of Unique Values in Each Categorical Column
unique_counts <- sapply(combined_data[sapply(combined_data, is.character)], function(x) length(unique(x)))

# Plotting the counts as a pie chart
pie(unique_counts, main = "Count of Unique Values in Each Categorical Column", col = rainbow(length(unique_counts)),
    labels = paste(names(unique_counts), ": ", unique_counts), cex = 0.8)

```

#### 2. Wordcloud of country & cities in data set:

```{r}
# Create a corpus from the "Country" column
country_corpus <- Corpus(VectorSource(combined_data$Country))

# Preprocess the text for country names (remove punctuation, convert to lowercase, remove stopwords)
suppressWarnings({
  country_corpus <- tm_map(country_corpus, content_transformer(tolower))
  country_corpus <- tm_map(country_corpus, removePunctuation)
  country_corpus <- tm_map(country_corpus, removeNumbers)
  country_corpus <- tm_map(country_corpus, removeWords, stopwords("english"))
})

# Define a custom function to remove empty documents from the corpus
removeEmptyDocs <- function(corpus) {
  empty_docs <- which(sapply(corpus, function(x) length(unlist(strsplit(as.character(x), " ")))) == 0)
  if (length(empty_docs) > 0) {
    corpus <- corpus[-empty_docs]
  }
  return(corpus)
}

# Remove empty documents from the corpus
suppressWarnings({
  country_corpus <- removeEmptyDocs(country_corpus)
})

# Convert corpus to a plain text document
country_text <- tm_map(country_corpus, content_transformer(as.character))

# Generate word cloud for countries with adjustments for long country names
wordcloud(country_text, min.freq = 1, random.order = FALSE, colors = brewer.pal(8, "Dark2"), 
          max.words = 100, scale=c(4, 0.5))


```

```{r}
# Create a corpus from the "City" column
city_corpus <- Corpus(VectorSource(combined_data$City))

# Preprocess the text for city names (remove punctuation, convert to lowercase, remove stopwords)
suppressWarnings({
  city_corpus <- tm_map(city_corpus, content_transformer(tolower))
  city_corpus <- tm_map(city_corpus, removePunctuation)
  city_corpus <- tm_map(city_corpus, removeNumbers)
  city_corpus <- tm_map(city_corpus, removeWords, stopwords("english"))
})

# Define a custom function to remove empty documents from the corpus
removeEmptyDocs <- function(corpus) {
  empty_docs <- which(sapply(corpus, function(x) length(unlist(strsplit(as.character(x), " ")))) == 0)
  if (length(empty_docs) > 0) {
    corpus <- corpus[-empty_docs]
  }
  return(corpus)
}

# Remove empty documents from the corpus
suppressWarnings({
  city_corpus <- removeEmptyDocs(city_corpus)
})

# Convert corpus to a plain text document
city_text <- tm_map(city_corpus, content_transformer(as.character))

# Generate word cloud for cities with adjustments for long city names
wordcloud(city_text, min.freq = 1, random.order = FALSE, colors = brewer.pal(8, "Dark2"), 
          max.words = 50, scale=c(2, 0.5))
```

#### 3. Histogram of distribution of numerical columns:

```{r}
# Loop through each numerical column to create histograms
for(column_name in numerical_columns) {
  # Print the name of the current column
  print(column_name)
  
  # Create a symbol from the string column name
  column_sym <- sym(column_name)
  
  # Plot histogram for the current numerical column using tidy evaluation
  p <- ggplot(combined_data, aes(x = !!column_sym)) + 
    geom_histogram(binwidth = 1, fill = "blue", color = "black") + 
    theme_minimal() + 
    labs(title = paste("Histogram of", column_name))
  
  # This will actually draw the plot
  print(p)
}


```

#### 4. Are there any significant differences in Cappuccino prices across different countries?

```{r}
# Filter the data to include only the top 10 countries by Cappuccino prices
top_10_countries <- combined_data %>%
  group_by(Country) %>%
  summarize(Avg_Cappuccino_Price = mean(Cappuccino)) %>%
  top_n(10, Avg_Cappuccino_Price) %>%
  pull(Country)

filtered_data <- combined_data %>%
  filter(Country %in% top_10_countries)

# Create a boxplot to visualize the distribution of Cappuccino prices across the top 10 countries
ggplot(filtered_data, aes(x = Country, y = Cappuccino)) +
  geom_boxplot(fill = "skyblue", color = "black") +
  labs(title = "Distribution of Cappuccino Prices Across Top 10 Countries",
       x = "Country",
       y = "Cappuccino Price (USD)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability

# Perform ANOVA to test for significant differences in Cappuccino prices across the top 10 countries
anova_result <- aov(Cappuccino ~ Country, data = filtered_data)
summary(anova_result)

```

##### Note: Yes, there are significant differences in Cappuccino prices across different countries according to the ANOVA test results.

#### 5. Geographical distribution of top 10 cities with high Movehub Ratings:

```{r}
# Order cities by Movehub Rating and select top 10
top_10_cities <- combined_data[order(combined_data$Movehub.Rating, decreasing = TRUE), ][1:10, ]

# Create Leaflet map
m <- leaflet(top_10_cities) %>% 
  addTiles() %>%  # Add default OpenStreetMap map tiles
  addCircleMarkers(
    lng = ~LONG, lat = ~LAT, 
    radius = ~sqrt(Movehub.Rating) * 3,  # Adjust circle marker size based on Movehub Rating
    color = "#4CAF50", fillColor = "#4CAF50", fillOpacity = 0.7,
    popup = ~paste("<b>", City, "</b>", "<br>", "<b>Movehub Rating:</b> ", Movehub.Rating)
  ) %>%
  addProviderTiles(providers$Esri.WorldTopoMap) %>%
  addScaleBar(position = "bottomleft") %>%
  addLegend(
    position = "bottomright",
    colors = "#4CAF50",
    labels = "Circle Radius (Movehub Rating)"
  ) %>%
  addEasyButton(easyButton(
    icon = "fa-info-circle", title = "Information",
    onClick = JS("function(btn, map) { alert('This map displays the top 10 cities based on Movehub Rating, with circle markers representing Movehub Rating.'); }")
  ))

# Display the map
m 

```

#### 6. Geographical distribution of top 10 cities with Quality.of.Life:

```{r}
# Order cities by Quality of Life and select top 10
top_10_cities <- combined_data[order(combined_data$Quality.of.Life, decreasing = TRUE), ][1:10, ]

# Create Leaflet map
m <- leaflet(top_10_cities) %>% 
  addTiles() %>%  # Add default OpenStreetMap map tiles
  addCircleMarkers(
    lng = ~LONG, lat = ~LAT, 
    radius = ~sqrt(Quality.of.Life) * 3,  # Adjust circle marker size based on Quality of Life
    color = "#2196F3", fillColor = "#2196F3", fillOpacity = 0.7,
    popup = ~paste("<b>", City, "</b>", "<br>", "<b>Quality of Life:</b> ", Quality.of.Life)
  ) %>%
  addProviderTiles(providers$Esri.WorldTopoMap) %>%
  addScaleBar(position = "bottomleft") %>%
  addLegend(
    position = "bottomright",
    colors = "#2196F3",
    labels = "Circle Radius (Quality of Life)"
  ) %>%
  addEasyButton(easyButton(
    icon = "fa-info-circle", title = "Information",
    onClick = JS("function(btn, map) { alert('This map displays the top 10 cities based on Quality of Life, with circle markers representing Quality of Life.'); }")
  ))

# Display the map
m 


```

#### 7. Geographical distribution of top 10 cities with Crime Rating:

```{r}
# Order cities by Crime Rating and select top 10
top_10_cities <- combined_data[order(combined_data$Crime.Rating), ][1:10, ]

# Create Leaflet map
m <- leaflet(top_10_cities) %>% 
  addTiles() %>%  # Add default OpenStreetMap map tiles
  addCircleMarkers(
    lng = ~LONG, lat = ~LAT, 
    radius = ~sqrt(Crime.Rating) * 3,  # Adjust circle marker size based on Crime Rating
    color = "#FF5722", fillColor = "#FF5722", fillOpacity = 0.7,
    popup = ~paste("<b>", City, "</b>", "<br>", "<b>Crime Rating:</b> ", Crime.Rating)
  ) %>%
  addProviderTiles(providers$Esri.WorldTopoMap) %>%
  addScaleBar(position = "bottomleft") %>%
  addLegend(
    position = "bottomright",
    colors = "#FF5722",
    labels = "Circle Radius (Crime Rating)"
  ) %>%
  addEasyButton(easyButton(
    icon = "fa-info-circle", title = "Information",
    onClick = JS("function(btn, map) { alert('This map displays the top 10 cities with the lowest Crime Rating, with circle markers representing Crime Rating.'); }")
  ))

# Display the map
m 

```

```{r}
#Creating new dataframe for Modelling: 
res <- combined_data[complete.cases(combined_data$LAT, combined_data$LONG), ] 

```

### Overall correlation:

```{r}
# Overall correlation
num.cols <- sapply(res, is.numeric)
corrPLOT <- corrplot(cor(res[,num.cols]), method='ellipse', order="AOE")

```

-   Movehub Rating has negative correlation with Pollution, Crime as one can expect
-   Other features give a positive correlation with Movehub Rating

#### (better) Correlation:

```{r}
# (better) Correlation
res <- data.frame(res %>% dplyr::select(-Quality.of.Life,-City,-Country))
num.cols <- sapply(res, is.numeric)
corrPLOT <- corrplot(cor(res[,num.cols]), method='number', order="AOE") 


```

-   The higher correlated features with Movehub.Rating are Purchase.Power and \`Avg.Disposable.Income
-   Gasoline does not show a strong correlation (to my surprise)
-   Cappuccino (I guess itâ€™s the average price) is almost as important as Health Care.

Overall, there are linear correlations between Movehub Rating and the other numerical features. So we may try as a first test a linear model.

### APPLYING MODEL TO PREDICT--\> Movehub Rating score :

```{r}
# Train Test Split
set.seed(101)
split <- sample.split(res$Movehub.Rating, SplitRatio = 0.7)
train <- subset(res, split == TRUE)
test <- subset(res, split == FALSE)

```

```{r}
# Function to plot the result of a given model and other information
plotModel <- function(mod) {
  # Create dataframe with prediction and real values
  mod.predictions <- predict(mod, test)
  mod.res <- cbind(mod.predictions, test$Movehub.Rating)
  colnames(mod.res) <- c('Predictions', 'True')
  mod.res <- as.data.frame(mod.res)
  
  # Make plots of residuals, etc.
  g1 <- ggplot(data = mod.res, aes(x = Predictions, y = True)) +
    geom_point() + xlim(50, 100) + ylim(50, 100) +
    geom_abline(intercept = 0, slope = 1, color = 'red')
  g2 <- ggplot(data = mod.res, aes(x = True - Predictions)) +
    geom_histogram(bins = 50)
  g3 <- ggplot(data = mod.res, aes(x = Predictions, y = True - Predictions)) +
    geom_point()
  
  # Arrange the plots
  grid.arrange(g1, g2, g3, nrow = 2, ncol = 2)
  
  # Calculate metrics
  mse <- mean((mod.res$True - mod.res$Predictions)^2)
  rmse <- mse^0.5
  SSE <- sum((mod.res$Predictions - mod.res$True)^2)
  SST <- sum((mean(test$Movehub.Rating) - mod.res$True)^2)
  R2 <- 1 - SSE / SST
  
  cat("MSE: %f RMSE : %f R^2 :%f", mse, rmse, R2)
}

```

#### -Linear model with all features:

```{r}
# Applying linear Regression
linModel <- lm(Movehub.Rating ~ ., data = train)
summary(linModel)

```

```{r}
# Plotting the graph 
plotModel(linModel)
```

#### -Linear model with stepwise regression:

From the summary of the linear model, we see that not all the features are significant. So we can try to improve this linear model by performing a stepwise selection of features in both direction.

```{r}
# Linear model with stepwise regression
step <- stepAIC(linModel, direction = "both")
step$anova

```

```{r}
finalModel <- lm(Movehub.Rating ~ Cappuccino + Gasoline + Avg.Rent + Purchase.Power + Health.Care, data = train)
summary(finalModel)

```

```{r}
# Plotting the graph of residuals for the final model
plotModel(finalModel)

```

```{r}
# Comparison between all features and selected ones
anova(linModel, finalModel)

```

##### Note: The model found with the stepwise regression did achieve a better R\^2 score (0.6508697 vs. 0.6145516)

```{r}


```
